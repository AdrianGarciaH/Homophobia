{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d01cf2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## for data\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "## for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "## for processing\n",
    "import re\n",
    "import nltk\n",
    "## for bag-of-words\n",
    "from sklearn import metrics, feature_extraction, feature_selection, model_selection, naive_bayes, pipeline, manifold, preprocessing\n",
    "## for explainer\n",
    "from lime import lime_text\n",
    "## for word embedding\n",
    "import gensim\n",
    "import gensim.downloader as gensim_api\n",
    "## for deep learning\n",
    "from tensorflow.keras import models, layers, preprocessing as kprocessing\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "## for bert language model\n",
    "import transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "24df72de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' The following shows the result of training various non-nerual network models on a cleaned version of the \\nKannada set transliterated so that all comments are in the Kannada script. models are trained on an tf-idf vectorizer\\nwith dimensionality reduction.'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' The following shows the result of training various non-nerual network models on a cleaned version of the \n",
    "Kannada set transliterated so that all comments are in the Kannada script. models are trained on an tf-idf vectorizer\n",
    "with dimensionality reduction.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10341ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data\n",
    "kan_train = pd.read_table(\"../../datasets/task_a/kan_sentiment_train.tsv\")\n",
    "kan_dev = pd.read_table(\"../../datasets/task_a/kan_sentiment_dev.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b391822a",
   "metadata": {},
   "outputs": [],
   "source": [
    "kan_train = kan_train.rename(columns={'category': 'y'})\n",
    "kan_dev = kan_dev.rename(columns={'category': 'y'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ebf2575",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Binduge saryagi ugithidira good go ahead  we a...</td>\n",
       "      <td>Mixed feelings</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>yen song guru ...super</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>my fevorat story</td>\n",
       "      <td>not-Kannada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Super ತೋಗರಿ ತೀಪ್ಪ</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ನಿಮ್ಮ ಮಾತುಗಳು ಅಕ್ಷರಶಃ ಸತ್ಯ... ನಿಮ್ಮ ಈ ಸಾಮಾನ್ಯ ...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>686</th>\n",
       "      <td>@Nandi Parthasarathi ನಿಮ್ಮ ಅಪ್ಪ ದೊಡ್ ಗಾಂಡು ಸೂಳೆಮಗ</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>687</th>\n",
       "      <td>Hugi guru badethawke</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>688</th>\n",
       "      <td>Trending no.1 wow</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>689</th>\n",
       "      <td>@Troll Stupid Fans naanu adikke kano helthirod...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>690</th>\n",
       "      <td>@JustAn Opinion ninu Tika mucchu...Evattu Kann...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>691 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text               y\n",
       "0    Binduge saryagi ugithidira good go ahead  we a...  Mixed feelings\n",
       "1                               yen song guru ...super        Positive\n",
       "2                                     my fevorat story     not-Kannada\n",
       "3                                    Super ತೋಗರಿ ತೀಪ್ಪ        Positive\n",
       "4    ನಿಮ್ಮ ಮಾತುಗಳು ಅಕ್ಷರಶಃ ಸತ್ಯ... ನಿಮ್ಮ ಈ ಸಾಮಾನ್ಯ ...        Positive\n",
       "..                                                 ...             ...\n",
       "686  @Nandi Parthasarathi ನಿಮ್ಮ ಅಪ್ಪ ದೊಡ್ ಗಾಂಡು ಸೂಳೆಮಗ        Negative\n",
       "687                               Hugi guru badethawke        Negative\n",
       "688                                  Trending no.1 wow        Positive\n",
       "689  @Troll Stupid Fans naanu adikke kano helthirod...        Positive\n",
       "690  @JustAn Opinion ninu Tika mucchu...Evattu Kann...        Positive\n",
       "\n",
       "[691 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kan_dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c3e7bb66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "fig.suptitle(\"y\", fontsize=12)\n",
    "kan_train.groupby(\"y\").count().plot(kind=\"barh\", legend=False, \n",
    "        ax=ax).grid(axis='x')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "064fe9df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the list of stopwords in Kannada\n",
    "with open('../stopwords-kn.txt') as file:\n",
    "    lines = file.readlines()\n",
    "    lines = [line.rstrip() for line in lines]\n",
    "\n",
    "lst_stopwords = lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "877b25b5",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'indictrans'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-c45b442a85b5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# transliterate all data from english scrip to kannada script\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mindictrans\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTransliterator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# instantiate the trasnliteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtrn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTransliterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'eng'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'kan'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuild_lookup\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'indictrans'"
     ]
    }
   ],
   "source": [
    "# transliterate all data from english scrip to kannada script\n",
    "from indictrans import Transliterator\n",
    "\n",
    "# instantiate the trasnliteration\n",
    "trn = Transliterator(source='eng', target='kan', build_lookup=True)\n",
    "\n",
    "# save the text column as a list in order to improve performance.\n",
    "orig_kn_train = (kan_train['text'].to_numpy()).tolist()\n",
    "\n",
    "# create and empty list, iterate through the list of text and append the transliterated text to our list.\n",
    "list_trans = []\n",
    "for i in range(len(orig_kn_train)):\n",
    "    list_trans.append(trn.transform(orig_kn_train[i]))\n",
    "    \n",
    "# append the transliterated texts as a column on original dataframe\n",
    "kan_train['text_trans'] = list_trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c399ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "kan_train_trans = kan_train.drop(['text'], axis=1)\n",
    "kan_train_trans.rename(columns={'text_trans':'text'}, inplace= True)\n",
    "kan_train_trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d020c9a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# do the same for the dev data\n",
    "# save the text column as a list in order to improve performance.\n",
    "orig_kn_dev = (kan_dev['text'].to_numpy()).tolist()\n",
    "\n",
    "# create and empty list, iterate through the list of text and append the transliterated text to our list.\n",
    "list_trans_dev = []\n",
    "for i in range(len(orig_kn_dev)):\n",
    "    list_trans_dev.append(trn.transform(orig_kn_dev[i]))\n",
    "    \n",
    "# append the transliterated texts as a column on original dataframe\n",
    "kan_dev['text_trans'] = list_trans_dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f4580d",
   "metadata": {},
   "outputs": [],
   "source": [
    "kan_dev_trans = kan_dev.drop(['text'], axis=1)\n",
    "kan_dev_trans.rename(columns={'text_trans':'text'}, inplace= True)\n",
    "kan_dev_trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ecb701",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Preprocess a string.\n",
    ":parameter\n",
    "    :param text: string - name of column containing text\n",
    "    :param lst_stopwords: list - list of stopwords to remove\n",
    ":return\n",
    "    cleaned text\n",
    "'''\n",
    "def utils_preprocess_text(text, lst_stopwords=None):\n",
    "    ## clean (convert to lowercase and remove punctuations and characters and then strip)\n",
    "    text = re.sub(r'[^\\w\\s]', '', str(text).lower().strip())\n",
    "            \n",
    "    ## Tokenize (convert from string to list)\n",
    "    lst_text = text.split()\n",
    "    ## remove Stopwords\n",
    "    if lst_stopwords is not None:\n",
    "        lst_text = [word for word in lst_text if word not in \n",
    "                    lst_stopwords]\n",
    "                \n",
    "    ## back to string from list\n",
    "    text = \" \".join(lst_text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e21014d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we can apply the preprocessing function to our data\n",
    "\n",
    "kan_train_trans[\"text_clean\"] = kan_train_trans[\"text\"].apply(lambda x: \n",
    "          utils_preprocess_text(x, lst_stopwords=lst_stopwords))\n",
    "\n",
    "kan_dev_trans[\"text_clean\"] = kan_dev_trans[\"text\"].apply(lambda x: \n",
    "          utils_preprocess_text(x, lst_stopwords=lst_stopwords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b530d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "kan_dev_trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b1afa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can define our training data and our dev data as well as targets\n",
    "train = kan_train_trans\n",
    "test = kan_dev_trans\n",
    "\n",
    "y_train = kan_train_trans['y'].values\n",
    "y_test = kan_dev_trans['y'].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b7e5ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for ensemble: \n",
    "results = pd.DataFrame(kan_dev_trans['y'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7b4d665",
   "metadata": {},
   "source": [
    "## Using Tf-Idf vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "926a58c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Count (classic BoW)\n",
    "#vectorizer = feature_extraction.text.CountVectorizer(max_features=10000, ngram_range=(1,2))\n",
    "\n",
    "## Tf-Idf (advanced variant of BoW)\n",
    "vectorizer = feature_extraction.text.TfidfVectorizer(max_features=10000, ngram_range=(1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33131140",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now run thse vectorizers on the train data\n",
    "corpus = train[\"text_clean\"]\n",
    "vectorizer.fit(corpus)\n",
    "X_train = vectorizer.transform(corpus)\n",
    "dic_vocabulary = vectorizer.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e7c5c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67412a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(X_train.todense()[:,np.random.randint(0,X_train.shape[1],100)]==0, vmin=0, vmax=1, cbar=False).set_title('Sparse Matrix Sample')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c9a8dd7",
   "metadata": {},
   "source": [
    "## reducing the vectorizers dimensionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2784f949",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reduce dimensionality through feature selection\n",
    "\n",
    "y = y_train\n",
    "X_names = vectorizer.get_feature_names()\n",
    "p_value_limit = 0.95\n",
    "\n",
    "dtf_features = pd.DataFrame()\n",
    "for cat in np.unique(y):\n",
    "    chi2, p = feature_selection.chi2(X_train, y==cat)\n",
    "    dtf_features = dtf_features.append(pd.DataFrame(\n",
    "                   {\"feature\":X_names, \"score\":1-p, \"y\":cat}))\n",
    "    dtf_features = dtf_features.sort_values([\"y\",\"score\"], \n",
    "                    ascending=[True,False])\n",
    "    dtf_features = dtf_features[dtf_features[\"score\"]>p_value_limit]\n",
    "X_names = dtf_features[\"feature\"].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f28b5df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for cat in np.unique(y):\n",
    "   print(\"# {}:\".format(cat))\n",
    "   print(\"  . selected features:\",\n",
    "         len(dtf_features[dtf_features[\"y\"]==cat]))\n",
    "   print(\"  . top features:\", \",\".join(\n",
    "dtf_features[dtf_features[\"y\"]==cat][\"feature\"].values[:10]))\n",
    "   print(\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e423dd51",
   "metadata": {},
   "source": [
    "## re-fitting the vectorizer on the new vocabulary gained through feature reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "609a97a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can now refit the vecotrizer on the corpus by giving this new set of words as input.\n",
    "# producing a smaller feature matrix and a shorter vocabulary.\n",
    "vectorizer = feature_extraction.text.TfidfVectorizer(vocabulary=X_names)\n",
    "vectorizer.fit(corpus)\n",
    "X_train = vectorizer.transform(corpus)\n",
    "dic_vocabulary = vectorizer.vocabulary_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee02af69",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86cf2a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(X_train.todense()[:,np.random.randint(0,X_train.shape[1],100)]==0, vmin=0, vmax=1, cbar=False).set_title('Sparse Matrix Sample')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83a4bf9a",
   "metadata": {},
   "source": [
    "# Training a cat boost classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c6f85a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "cat = CatBoostClassifier(\n",
    "    iterations=1000, \n",
    "    learning_rate=1.2, \n",
    "    #loss_function='CrossEntropy'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a2620bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "## pipeline\n",
    "model_cat = pipeline.Pipeline([(\"vectorizer\", vectorizer),  \n",
    "                           (\"classifier\", cat)])\n",
    "## train classifier\n",
    "model_cat[\"classifier\"].fit(X_train, y_train)\n",
    "## test\n",
    "X_test = test[\"text_clean\"].values\n",
    "predicted = model_cat.predict(X_test)\n",
    "results['cat_boost_cleaned_tfidf'] = predicted\n",
    "predicted_prob = model_cat.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b4b180",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets see our model performance\n",
    "classes = np.unique(y_test)\n",
    "y_test_array = pd.get_dummies(y_test, drop_first=False).values\n",
    "    \n",
    "## Accuracy, Precision, Recall\n",
    "accuracy = metrics.accuracy_score(y_test, predicted)\n",
    "auc = metrics.roc_auc_score(y_test, predicted_prob, \n",
    "                            multi_class=\"ovr\")\n",
    "print(\"Accuracy:\",  round(accuracy,2))\n",
    "print(\"Auc:\", round(auc,2))\n",
    "print(\"Detail:\")\n",
    "print(metrics.classification_report(y_test, predicted))\n",
    "    \n",
    "## Plot confusion matrix\n",
    "cm = metrics.confusion_matrix(y_test, predicted)\n",
    "fig, ax = plt.subplots()\n",
    "sns.heatmap(cm, annot=True, fmt='d', ax=ax, cmap=plt.cm.Blues, \n",
    "            cbar=False)\n",
    "ax.set(xlabel=\"Pred\", ylabel=\"True\", xticklabels=classes, \n",
    "       yticklabels=classes, title=\"Confusion matrix\")\n",
    "plt.yticks(rotation=0)\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=2)\n",
    "## Plot roc\n",
    "for i in range(len(classes)):\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y_test_array[:,i],  \n",
    "                           predicted_prob[:,i])\n",
    "    ax[0].plot(fpr, tpr, lw=3, \n",
    "              label='{0} (area={1:0.2f})'.format(classes[i], \n",
    "                              metrics.auc(fpr, tpr))\n",
    "               )\n",
    "ax[0].plot([0,1], [0,1], color='navy', lw=3, linestyle='--')\n",
    "ax[0].set(xlim=[-0.05,1.0], ylim=[0.0,1.05], \n",
    "          xlabel='False Positive Rate', \n",
    "          ylabel=\"True Positive Rate (Recall)\", \n",
    "          title=\"Receiver operating characteristic\")\n",
    "ax[0].legend(loc=\"lower right\")\n",
    "ax[0].grid(True)\n",
    "    \n",
    "## Plot precision-recall curve\n",
    "for i in range(len(classes)):\n",
    "    precision, recall, thresholds = metrics.precision_recall_curve(\n",
    "                 y_test_array[:,i], predicted_prob[:,i])\n",
    "    ax[1].plot(recall, precision, lw=3, \n",
    "               label='{0} (area={1:0.2f})'.format(classes[i], \n",
    "                                  metrics.auc(recall, precision))\n",
    "              )\n",
    "ax[1].set(xlim=[0.0,1.05], ylim=[0.0,1.05], xlabel='Recall', \n",
    "          ylabel=\"Precision\", title=\"Precision-Recall curve\")\n",
    "ax[1].legend(loc=\"best\")\n",
    "ax[1].grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52b9eb5a",
   "metadata": {},
   "source": [
    "# Training a Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f991bd58",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "forest = RandomForestClassifier(max_depth=150, n_estimators=30, max_features=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "870a76ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "## pipeline\n",
    "model_forest = pipeline.Pipeline([(\"vectorizer\", vectorizer),  \n",
    "                           (\"classifier\", forest)])\n",
    "## train classifier\n",
    "model_forest[\"classifier\"].fit(X_train, y_train)\n",
    "## test\n",
    "X_test = test[\"text_clean\"].values\n",
    "predicted = model_forest.predict(X_test)\n",
    "results['forest_cleaned_tfidf'] = predicted\n",
    "predicted_prob = model_forest.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "951550ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets see our model performance\n",
    "classes = np.unique(y_test)\n",
    "y_test_array = pd.get_dummies(y_test, drop_first=False).values\n",
    "    \n",
    "## Accuracy, Precision, Recall\n",
    "accuracy = metrics.accuracy_score(y_test, predicted)\n",
    "auc = metrics.roc_auc_score(y_test, predicted_prob, \n",
    "                            multi_class=\"ovr\")\n",
    "print(\"Accuracy:\",  round(accuracy,2))\n",
    "print(\"Auc:\", round(auc,2))\n",
    "print(\"Detail:\")\n",
    "print(metrics.classification_report(y_test, predicted))\n",
    "    \n",
    "## Plot confusion matrix\n",
    "cm = metrics.confusion_matrix(y_test, predicted)\n",
    "fig, ax = plt.subplots()\n",
    "sns.heatmap(cm, annot=True, fmt='d', ax=ax, cmap=plt.cm.Blues, \n",
    "            cbar=False)\n",
    "ax.set(xlabel=\"Pred\", ylabel=\"True\", xticklabels=classes, \n",
    "       yticklabels=classes, title=\"Confusion matrix\")\n",
    "plt.yticks(rotation=0)\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=2)\n",
    "## Plot roc\n",
    "for i in range(len(classes)):\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y_test_array[:,i],  \n",
    "                           predicted_prob[:,i])\n",
    "    ax[0].plot(fpr, tpr, lw=3, \n",
    "              label='{0} (area={1:0.2f})'.format(classes[i], \n",
    "                              metrics.auc(fpr, tpr))\n",
    "               )\n",
    "ax[0].plot([0,1], [0,1], color='navy', lw=3, linestyle='--')\n",
    "ax[0].set(xlim=[-0.05,1.0], ylim=[0.0,1.05], \n",
    "          xlabel='False Positive Rate', \n",
    "          ylabel=\"True Positive Rate (Recall)\", \n",
    "          title=\"Receiver operating characteristic\")\n",
    "ax[0].legend(loc=\"lower right\")\n",
    "ax[0].grid(True)\n",
    "    \n",
    "## Plot precision-recall curve\n",
    "for i in range(len(classes)):\n",
    "    precision, recall, thresholds = metrics.precision_recall_curve(\n",
    "                 y_test_array[:,i], predicted_prob[:,i])\n",
    "    ax[1].plot(recall, precision, lw=3, \n",
    "               label='{0} (area={1:0.2f})'.format(classes[i], \n",
    "                                  metrics.auc(recall, precision))\n",
    "              )\n",
    "ax[1].set(xlim=[0.0,1.05], ylim=[0.0,1.05], xlabel='Recall', \n",
    "          ylabel=\"Precision\", title=\"Precision-Recall curve\")\n",
    "ax[1].legend(loc=\"best\")\n",
    "ax[1].grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8302812",
   "metadata": {},
   "source": [
    "# fitting a logistic regression classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c92d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "log =LogisticRegression(random_state=0, max_iter= 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d31dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## pipeline\n",
    "model_log = pipeline.Pipeline([(\"vectorizer\", vectorizer),  \n",
    "                           (\"classifier\", log)])\n",
    "## train classifier\n",
    "model_log[\"classifier\"].fit(X_train, y_train)\n",
    "## test\n",
    "X_test = test[\"text\"].values\n",
    "predicted = model_log.predict(X_test)\n",
    "results['logistic_reg_cleaned_tfidf'] = predicted\n",
    "predicted_prob = model_log.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd2f771c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets see our model performance\n",
    "classes = np.unique(y_test)\n",
    "y_test_array = pd.get_dummies(y_test, drop_first=False).values\n",
    "    \n",
    "## Accuracy, Precision, Recall\n",
    "accuracy = metrics.accuracy_score(y_test, predicted)\n",
    "auc = metrics.roc_auc_score(y_test, predicted_prob, \n",
    "                            multi_class=\"ovr\")\n",
    "print(\"Accuracy:\",  round(accuracy,2))\n",
    "print(\"Auc:\", round(auc,2))\n",
    "print(\"Detail:\")\n",
    "print(metrics.classification_report(y_test, predicted))\n",
    "    \n",
    "## Plot confusion matrix\n",
    "cm = metrics.confusion_matrix(y_test, predicted)\n",
    "fig, ax = plt.subplots()\n",
    "sns.heatmap(cm, annot=True, fmt='d', ax=ax, cmap=plt.cm.Blues, \n",
    "            cbar=False)\n",
    "ax.set(xlabel=\"Pred\", ylabel=\"True\", xticklabels=classes, \n",
    "       yticklabels=classes, title=\"Confusion matrix\")\n",
    "plt.yticks(rotation=0)\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=2)\n",
    "## Plot roc\n",
    "for i in range(len(classes)):\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y_test_array[:,i],  \n",
    "                           predicted_prob[:,i])\n",
    "    ax[0].plot(fpr, tpr, lw=3, \n",
    "              label='{0} (area={1:0.2f})'.format(classes[i], \n",
    "                              metrics.auc(fpr, tpr))\n",
    "               )\n",
    "ax[0].plot([0,1], [0,1], color='navy', lw=3, linestyle='--')\n",
    "ax[0].set(xlim=[-0.05,1.0], ylim=[0.0,1.05], \n",
    "          xlabel='False Positive Rate', \n",
    "          ylabel=\"True Positive Rate (Recall)\", \n",
    "          title=\"Receiver operating characteristic\")\n",
    "ax[0].legend(loc=\"lower right\")\n",
    "ax[0].grid(True)\n",
    "    \n",
    "## Plot precision-recall curve\n",
    "for i in range(len(classes)):\n",
    "    precision, recall, thresholds = metrics.precision_recall_curve(\n",
    "                 y_test_array[:,i], predicted_prob[:,i])\n",
    "    ax[1].plot(recall, precision, lw=3, \n",
    "               label='{0} (area={1:0.2f})'.format(classes[i], \n",
    "                                  metrics.auc(recall, precision))\n",
    "              )\n",
    "ax[1].set(xlim=[0.0,1.05], ylim=[0.0,1.05], xlabel='Recall', \n",
    "          ylabel=\"Precision\", title=\"Precision-Recall curve\")\n",
    "ax[1].legend(loc=\"best\")\n",
    "ax[1].grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7b8dcce",
   "metadata": {},
   "source": [
    "# training a k-neighboot classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d67f0580",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "neigh = KNeighborsClassifier(n_neighbors=5, weights='distance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d565d9bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "## pipeline\n",
    "model_neigh = pipeline.Pipeline([(\"vectorizer\", vectorizer),  \n",
    "                           (\"classifier\", neigh)])\n",
    "## train classifier\n",
    "model_neigh[\"classifier\"].fit(X_train, y_train)\n",
    "## test\n",
    "X_test = test[\"text\"].values\n",
    "predicted = model_neigh.predict(X_test)\n",
    "results['k-nearest_cleaned_tfidf'] = predicted\n",
    "predicted_prob = model_neigh.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11aa1e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets see our model performance\n",
    "classes = np.unique(y_test)\n",
    "y_test_array = pd.get_dummies(y_test, drop_first=False).values\n",
    "    \n",
    "## Accuracy, Precision, Recall\n",
    "accuracy = metrics.accuracy_score(y_test, predicted)\n",
    "auc = metrics.roc_auc_score(y_test, predicted_prob, \n",
    "                            multi_class=\"ovr\")\n",
    "print(\"Accuracy:\",  round(accuracy,2))\n",
    "print(\"Auc:\", round(auc,2))\n",
    "print(\"Detail:\")\n",
    "print(metrics.classification_report(y_test, predicted))\n",
    "    \n",
    "## Plot confusion matrix\n",
    "cm = metrics.confusion_matrix(y_test, predicted)\n",
    "fig, ax = plt.subplots()\n",
    "sns.heatmap(cm, annot=True, fmt='d', ax=ax, cmap=plt.cm.Blues, \n",
    "            cbar=False)\n",
    "ax.set(xlabel=\"Pred\", ylabel=\"True\", xticklabels=classes, \n",
    "       yticklabels=classes, title=\"Confusion matrix\")\n",
    "plt.yticks(rotation=0)\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=2)\n",
    "## Plot roc\n",
    "for i in range(len(classes)):\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y_test_array[:,i],  \n",
    "                           predicted_prob[:,i])\n",
    "    ax[0].plot(fpr, tpr, lw=3, \n",
    "              label='{0} (area={1:0.2f})'.format(classes[i], \n",
    "                              metrics.auc(fpr, tpr))\n",
    "               )\n",
    "ax[0].plot([0,1], [0,1], color='navy', lw=3, linestyle='--')\n",
    "ax[0].set(xlim=[-0.05,1.0], ylim=[0.0,1.05], \n",
    "          xlabel='False Positive Rate', \n",
    "          ylabel=\"True Positive Rate (Recall)\", \n",
    "          title=\"Receiver operating characteristic\")\n",
    "ax[0].legend(loc=\"lower right\")\n",
    "ax[0].grid(True)\n",
    "    \n",
    "## Plot precision-recall curve\n",
    "for i in range(len(classes)):\n",
    "    precision, recall, thresholds = metrics.precision_recall_curve(\n",
    "                 y_test_array[:,i], predicted_prob[:,i])\n",
    "    ax[1].plot(recall, precision, lw=3, \n",
    "               label='{0} (area={1:0.2f})'.format(classes[i], \n",
    "                                  metrics.auc(recall, precision))\n",
    "              )\n",
    "ax[1].set(xlim=[0.0,1.05], ylim=[0.0,1.05], xlabel='Recall', \n",
    "          ylabel=\"Precision\", title=\"Precision-Recall curve\")\n",
    "ax[1].legend(loc=\"best\")\n",
    "ax[1].grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5505401",
   "metadata": {},
   "source": [
    "# Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a7fc05",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.replace(['Negative', 'Positive','not-Kannada', 'Mixed feelings','unknown state' ], [0,1,2,3,4], inplace=True)\n",
    "results['trabs_majority_label_tfidf'] = results[results.columns[1:]].mode(axis=1)[0].astype(int)\n",
    "results.replace([0,1,2,3,4], ['Negative', 'Positive','not-Kannada', 'Mixed feelings','unknown state' ], inplace=True)\n",
    "results.to_csv('kan_results_cleaned_tfidf.tsv', sep=\"\\t\", index = False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec27f2a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot confusion matrix\n",
    "print(metrics.classification_report(results['y'], results['majority_label']))\n",
    "cm = metrics.confusion_matrix(results['y'], results['majority_label'])\n",
    "fig, ax = plt.subplots()\n",
    "sns.heatmap(cm, annot=True, fmt='d', ax=ax, cmap=plt.cm.Blues, \n",
    "            cbar=False)\n",
    "ax.set(xlabel=\"Pred\", ylabel=\"True\", xticklabels=classes, \n",
    "       yticklabels=classes, title=\"Confusion matrix\")\n",
    "plt.yticks(rotation=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae1c6882",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
